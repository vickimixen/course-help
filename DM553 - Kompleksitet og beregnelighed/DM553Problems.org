* Week 1
** 1.6, 1.7
[[./0207-01.pdf]]
** Q1
*** a
Bring g, go back bring w, bring back g, bring c, go back, take g. QED.
*** b
[[./0207-02.pdf]]
* Week 2
** 1.16-1.21(b)
[[./solutions/0215.pdf]]
Note that in 1.16b we missed the epsilon transition some number of times. 
** 1.20
| Sub Ex | Mem 1 | Mem 2                    | NMem 1 | NMem 2 |
| a      | eps   | ab                       | ba     | aba    |
| b      | ab    | abab                     | ba     | aabb   |
| c      | eps   | aaaaa                    | ab     | aaaab  |
| d      | aaa   | aaaaaa                   | aa     | abba   |
| e      | aba   | aaba abababababbbbaaabbb | ab     | babbb  |
| f      | aba   | bab                      | a      | b      |
| g      | ab    | b                        | a      | ba     |
| h      | a     | ba                       | eps    | Nil    |
Note that h generates Sigma^*.
** 1.18
| Sub ex | expr                                                                                     |
| a      | $1 \Sigma^{*} 0$                                                                         |
| b      | $\Sigma^* 1 \Sigma^{*}1 \Sigma^{*}1 \Sigma^{*}$                                          |
| c      | $\Sigma^{*}0101\Sigma^{*}$                                                               |
| d      | $(1 \cup 0)(1 \cup 0)0\Sigma^{*}$                                                        |
| e      | $(0(00 \cup 01 \cuo 10 \cup 11)^{*}) \cup ((10 \cup 11)(00 \cup 01 \cuo 10 \cup 11)^{*}) |
| f      | Compliment of: $\Sigma^{*}110\Sigma^{*}$                                                 |
| g      | $(1 \cup 0)(1 \cup 0)(1 \cup 0)(1 \cup 0)(1 \cup 0)$                                     |
** 1.29
*** a
Take $n = p$, and then we must have $y$ all 0's, so when we repeat that we get
more 0's than 1's or 2's, so it is not in the language
*** b
Use the same argument as in example 1.75, p. 81
** 1.30
In 1.73 we have an equal amount of 0's and 1's, we are not limited to that in
this case. I would recommend the student that came up with this proof to read up
on what regexp are.
** 1.36
Take a NFA for A, reverse every arrow, add a new starting state, with
epsilon-paths to all the old accepted states, and make the old starting state
our new accepting state.

Then note that if a string w was recognized by the old NFA that means that there
exists a path P in the NFA s.t. it ends in an accepted state. Now note that by
having reversed every arrow P^R is now a path in NFA' (the new one) and thus
NFA' recognise w^R. To see it only recognise these strings apply a similar
argument for there not being a path in NFA'.
* Week 3
** 1.35
Consider the finite auto meta A for A. Then note that we can reverse A (A') and
still have a regular language. Note that we can now ask for any path in A' if it
is also in B-reverse. If it is we consider that a final state in our final
autometa. This gives us a machine the recognise those strings that are in A if
we concatenate them with some string in B.

In class:
L reg means there is a DFA for L. 
** 1.51
*** a
Use pumping lemma, pick string with n>p, then note that xy consists of only 0's.
Thus we can pump it and note that we get too many/too few 0's in the first part.
*** c
Consider intersection with the regular language 0*1*0*, which is regular (we
have shown this). Note that the intersection is (a), which we know is not
regular, so this is not regular
*** d
Can we just pick 0^p10^p, and then use pumping lemma? No we cannot, since we
will just have that our middle string is something new. Instead we consider
0^p11o^p1. Then this will work.
** 2.2
*** a
Note that the intersection of these two languages are exactly the one shown
being non context free en 2.36 p. 128.
*** b
Consider a context free language. We can write it as a union of two context free
languages (if nothing else, then itself and the emptylanguage). Now if we take
the compliment of it we can use DeMorgans law to write it as A' \cap B', but
since we know from a that CFL's are not closed under intersection we cannot
assume that this is a CFL, and thus we cannot assume that A is closed under
compliments.
** 2.4
*** a
S  -> S' 1 S' 1 S' 1 S'
S' -> S' S' | 0 | 1 | eps
*** b
S  -> 0 S' 0 | 1 S' 1 | eps
S' -> S' S' | 0 | 1 | eps
*** c
S -> 0 S' | 1 S'
S' -> S'S' | 00 | 01 | 10 | 11
*** d
S -> 0 | 0S0 | 0S1 | 1S0 | 1S1
*** e
S -> eps | 0 | 1 | 0S0 | 1S1
*** f
No rules? As S -> eps is not a the empty set. 
** 2.6
*** b
Note that the language could be generated by: S -> eps | a S b thus we can
generate the compliment by note that the compliment has the form of {a^n b^m | n
\ne m} \cup ((b \cup a)* ba (b \cup a)*). Then we can simply write grammas for
each of these.
*** d
S -> S' # B # S'
S' -> aS' | bS' | # S' | eps
B -> aBa | bBb | # S' #
We did not consider the case where i \ne j. Nor the one with an empty string, thus we just need to add eps to the last one.
** 2.14
First we add the start variable S, and
S -> A
Then we remove the lowest epsilon rule, and instead add
A -> BA | AB | A
Next we remove the other epsilon and instead add
A -> B 
This gives us
S -> A
A -> BAB | B | BA | AB | A 
B -> 00
Next we need to remove the unit rule A -> A and A -> B. Instead we add 
A -> 00
Finally we need to remove A -> BAB, To do this we instead create the rules
A -> B U1 
U1 -> A B
This gives us the final gramma:
S -> A
A -> BU1 | 00 | BA | AB | B U1
U1 -> A B
B -> 00
I forgot that we should only have 1 letter as an endpoint, so I should have replaced the final rule with B -> CC, C -> 0. Finally I also forgot to make the starting variable only dependent on one.
** 2.16
For union note that we simply add a new starting point that can go to either A
or B's starting point. For concatenation we instead add S -> S1 S2, with S1, S2
being the starting points for the two languages. For star we add S -> eps | S1 S
with S1 being the original starting point.
** 2.32
** 2.38
n-1 steps to generate all the symbols needed, then n to generate all the
letters.
** 2.42
*** a
Take n > p, then vxz can only contain 0*, 1* or 0*1* (of some combination). Note
that in any case we will end up without all having coefficients n.
*** b
Same procedure. Note that for all intents and purposes we could consider this
being 3 different numbers. 
*** c
Pick B^pa^p # b^pa^p, and note that to make this work we might need to take i
= 0.
* Week 4
** 2.58
See file. Note that idea is that it makes sure that there are at least as many
digits before the last 1 as there is after it.
[[./solutions/0228.pdf]]
** 2002 p2
Consider an DFA for L. The note that it has only one starting state (which is
not accepted), and that from there we have n arrows pointing out (where n is the
number of letters in the language). We construct a NFA for L~, by creating a new
starting state, that goes to the destinations of the arrows with an epsilon.
Thus we get exactly the words where we could add a letter in front of the word
and end up in L.
** 2002 p4
*** a
Note that a B always give one more B or b than it gives a or A's. It might also
give any number of S'es. The same goes for A with giving one more A or a.
Finally note that an S gives the same number of (a or A) and (B or b)'s. Thus,
since our starting rule is S, we end up with en equal amount of a's and b's.
*** b
Under assumption of being able to write multiple symbols onto the stack we let
it write two a's for every a eaten. After finishing eating a's we let it go on
with either an epsilon-transition to two different states, one where it eats two
a's for each b or one where it eats one. From here it can go on iff it has
finished eating the stack and b's at the same time.
[[./solutions/0228.pdf]]
** 2005 p3
*** a
S -> cB
B -> aBb (caBb)
B -> S (caSb)
S -> cA (cacAb)
A -> cbA (caccbAb)
A -> b (caccbbb)
*** b
{c(cb)^n b | n > 0} is an infinite set of strings inside G. They can be generated using first an S -> cA, then n many A -> cbA and finally an A -> b.
** 2007 p4
*** a
Note that we simply need at least as many a's as b's. 
S -> A B | eps | 
A -> a A | a A b | eps
B -> B a | b B a | eps
*** b
Nej, i = p, so j =p^2. Note that if v,y is in only a or b's it doesn't work.
Further note that thus v is only a's and y is only b's, otherwise we get out of
order. Further note that we now take i = 0, and then we have the string
a^p-nb^p^2-m. Either this fails, or (p-n)^2 = p^2 - 2pn + n^2 = p^2 - m, so m =
2pn - n^2. Instead we could take i = 2 we have a^p+nb^p^2+m. Thus (p+n)^2 =
p^2 + 2pn + n^2 = p^2 + m, so m = 2pn +n^2. However this implies that 2pn - n^2
= 2pn + n^2, so n = 0 and m = 0, however this is a contradiction to |uy| > 0.
** 2008 p2
*** a
Take n = k = p, and m = 2p. Then note that by the pumping lemma x and y are
inside the a's, since |xy| < p. Thus taking i = 2 we have n > p, so n + k > 2p =
m, so it is no longer in the language. Thus L is not regular. 
*** b
Yes, it is easy to design both a PDA and a grammar. We will here use a grammar;
S -> a S c | S'
S' -> b S' c | eps
** 2010 p2
*** a
Take i = p, and repeat it a sufficient amount of times.
*** b
We simply construct one such that we simply make sure that we never take an a without taking a b or c.
S -> a S c | S c | S'
S' -> a S' b | S' b | eps
*** c
No, it does not contain any strings with the letters out of order, so i.e. ba is
in non of the lagnuages.
*** d
[[./solutions/0228.pdf]]
* Week 5
** 3.2
*** b
We start in q_1, and see a 1 so we change it to an x and go right and to state
1_3, where we see a #, so we go right and to state 1_5. Here we see a 1, which
we change to an x and go left, where we see a # so we go Left in q_7. Then we go
left, again to q_7. Then we see an x and go right and to q_1. Here we see a #
and go R to q_8. We go left again in q_8 and see an empty spot, so we enter
q_accept.
*** c
Same as before until we stand in q_7, and see a symbol that we cannot
understand, so we go to q_reject.
*** d
We once again do the same for the 1's, and when we are back at q_1 we see a 0,
that we change to x and go elft to q_2. Then we see a # and go right to q_4. We
skip a x and stay in q_4. Then we see a 1, which means we go to q_reject.
** 3.7
Possibly because of the otherwise reject, as we will never finish testing
variables, and will thus never reject. In general it makes no sense to say "on
all these settings" in this case.
** 3.8
*** a
1. Mark the first unmarked 1 on the tape. If no 1 found then go to 4.
2. Go to start of tape, and mark the first unmarked 0 on the tape. If no
   unmarked 0 found reject.
3. Go to start of tape, and go to 1.
4. Go to start of tape, scan the tape. If any unmarked symbol is found reject,
   otherwise accept.
*** b
1. Mark the first unmarked 1 on the tape. If no 1 found go to 4.
2. Go to start of tape, and mark two unmarked 0's. If there is not two such 0's
   reject.
3. Go to start of tape, and go to 1.
4. Go to start of tape, scan the tape. If any unmarked symbol is found reject,
   otherwise accept.
*** c
Same a b, but with reversed rejects and accepts.
** Describe $L = {a^nb^{n!}|n \ge 1}$.
Lets work it out recursively. In the case where n = 2 we could simply mark the
first, take a b for it and then mark the 2nd take a b for it.

If we have n = 3 we could mark the first, then mark the 2nd with some other
symbol, remove one for the unmarked, then mark the 3rd and remove for that. Then
we move the first mark the the 2nd one etc.

??
*** In class
First we mark every n'th b. Then when we are done we remove an a, and mark every
(n-1)'th of the marked b's. Then we again remove an a etc. In practise this is
the same as asking if the number of b's can be divided with n, n-1, n-2, ... at
the same time. Note that we should make sure we always end up with the very last b marked. 

** 2002 p5
The machine starts on the left-most symbol (otherwise we move it to that
position). From here it should start scanning the symbol, remembering the last
symbol it has read. If that at any point is an 'a' and it scans a 'b' it should
replace that 'b' with an 'a' and move on (still considering this symbol as being
a 'b' for state purposes). When it get to an   it should go one pack, and go to
q_accept.
* Week 6
** 3.15
*** a
Like in the answer section.
*** b
Simulate first M1, if this arrives at an accepting state start simulating M2. If
this arrives in an accepting state accept. If either rejects, reject. If either
ends in an infinite loop so does M'.

Note that we do not go trough our word symbol by symbol. Instead we could
consider every possible splitting, but make sure to this like in the previous
example, since we do not know it halts.

An easier way to do this: Split the word in two parts, and use a non
deterministic TM to check if there is any such split that works.
*** c
If empty string accept. Otherwise simulate M1 and if M1 arrives in an accepting
state accept if the string is finished, otherwise continue running on w. If M1
rejects, reject. If it loops so does we.

Same problem as the last one, but we can again simply consider every possible
way to split the word (which is 2^|w|-1 ways.)
*** d
Simulate M1 and M2 in parallel, alternating each step. If both arrives at an
accepting state accept, if either rejects reject, if both loops we end up
looping. Again, if w is in the language we stop after an finite number of steps.
** 3.16
Pretty much the same, but we have to argue that the decide in the case that it
is reject. Note that this follows since the original TMs are deciders.
** 3.18
Idea: Clear that we can simulate a ordinary one in double infinite way. Consider
a mapping of the positive entries to 2n, and the negative entries to 2n-1. Then
we 'simply' need to update our TM such that it takes double steps, and a special
case then we going 'left' from 0 it should go one right, and then we should
still go two steps, but in opposite directions.

Or even easier to do it with a 2-tape TM.
** 3.22
*** a
Showing b shows this indirectly.
*** b
Consider that we first push the entire string down on T1, then we should push it
to T1 s.t. we are now in a case where we can consider T2 all of the tape right
of us, and T1 all of the tape left of us. Now moving around on the tape is
equivalent to moving a symbol from T1 to T2 or from T2 to T1. Thus we have a TM.
Since we have shown this is stronger than a PDA we are done.
** Ex 1
* Week 7
** 4.2
We can make a DFA from the regex, and from the book we have a TM for checking
equality, which we would use.
** 4.3
Consider the trivial DFA for \Sigma^*, that just accepts. Now we consrtuct a TM
that first checks of A is a DFA (if not reject) which is clearly decidable, and
then we use EQ_{DFA} on A and the trivial DFA. If they accept accept, if not
reject.
** 4.4
Just construc A \ Ø=\epsilon, and then check if this is empty. If it is not then
reject, else accept. We should check if \epsilon is in the language first, which
we can.

I missunderstood it, it just needs to generate \epsilon, so we can just use
A_{CFG} from p. 198.
** 4.8
Just list it (1,1,1) -> (1,1,2) -> (1,2,1) -> (1,2,2) -> (2,1,1) -> (2,1,2) ->
(2,2,1) -> ...

In essence just think of it as having a 3D plot, and then going the diagonals.
Or just use 1 2D, and add a negative axis that we also use for the 3rd
coordinate.
** 4.11
The problem would be L(TM) = {<G><A> ~|~ G CFG, A Variable in G and G is usable}
** 4.20
Note that M is the same as M^R, so we can just build M^R, and then use the
equality TM, to check if they are equal.
** 4.25
Pumping length? Maybe 2 pumping length, since we have to include them having
different loops.


** 4.29
Note that it is enough to show that $R \cap S' = \emptyset$. 

** 4.31
It is enough to consider all words of pumping length, and if any of them work it
is infinite, if not it is finite.

** 2010 p. 3

*** a
Disprove, consider \Sigma^* \cap \Sigma^* = \Sigma^* which is regular.

*** b
Disprove, consider a non-regular, and its compliment then the union is \Sigma^*
so regular.

*** d
Yes, note that a finite language is regular, so also context-free and
context-free languages are closed under union.

** 2011 p. 4

*** a
Just go to the case where there is longer than p between fib numbers.

*** b
Consider 3 tape TM, and store the previous two fibonnaci numbers on T2 nad T3,
and the simply remove the next fib number every time.

Or just be smart about marking a single tape. 

** Assignment 1
Looks mostly like we got it right.
* Week 9+10
** 5.10
Assuming it is mapping reducible it follows from 5.28 that it is recognizable.
Assuming it is recognizable can we simply reduce by sending A_TM a <TN><w> s.t.
TN accepts w if

*** At TA Lecture:
Let $TM_A$ be a TM for A. Then note that $f: w \rightarrow <TM_A,w>$ is a
mapping reduction that does the job.

For the other direction it follows from 5.28.
** 5.11
Note that if it is mapping reducible it is clear that $A$ is recognizable. 

For the other direction simply make a function as follows
\begin{align}
f: w \mapsto
\begin{choose}
01 & \text{if} w \in A\\
10 & \text{otherwise}
\end{choose}
\end{align}
Where we can check if $w \in A$ since $A$ is recognizable. 
** 5.18
*** a
Empty language and Sigma^* shows non-triviality. It is a property of the
language. Thus undecidable
*** b
Empty language, and sigma^*. Once again property of language.
*** c
Same.
** 2011 p. 5
*** 1
No, Rice's fav. languages.
*** 2
Same
*** 3
undecidable? But not by Rice's. 

Note that we know that the question of accepting the empty string is undecidable
we can reduce it to this problem by asking if m accepts every strength of length
less than equal 0.
*** 4
This would be possible with a deterministic one, but I don't know with a NDTM.
It might be possible to just concider a 2-tape NDTM, where we count up on the
2nd tape and then if we have any case where it stops before having taken k steps
we rejects, otherwise accept (always stop when we get over k on 2nd tape, so it
always stops).
*** 5
Decidable? Since M has a finite number, n, of stages we only need to simulate
n*k steps, and then it has either decided the string or it must have repeated a
stage at least k times so we can accept. (note that we should keep track of how
many times we visit each stage so we can decide it even if it stops before t*k
steps)
*** 6
Undecidable, since it is only ONE state we are interested in.

We can reduce the problem of weather a TM stops on a given input to this. We add
a new state q^*, and instead of qaccept or qreject we go to q*, and then visit
all states k time. Now if the TM was not going to stop it will never visit q* so
our original problem will accept (we reject) if it stops out OGTM will reject,
so we accept.

Since A_HALT is undecidable so must the one now be.
** 2010 p. 5
*** 1
rice's say no. Consider a^nb^n, and \emptyset.
*** 2
Decidable, find |w| as we do in excercise, and then simply fucking count the
bloody states.
*** 3
This is clearly decidable, since Ø is such a language, so we can always say yes.
*** 4
Decidable
*** 5
undecidable, since if it was decidable we can map reduce TM_HALT to this
problem, by just running the same TM twice. 
*** 6
Undecidable, just consider the language Ø and the lagnuage {a^n|0<n<=k}. 
** 2000 p. 4
*** 1
We build M' that simply accepts w if M stops on w. Now lets note that this is
undecidable by Rices. I M stopped we could decide M' on dm17, but we cannot. 
*** 2
Note that we cannot decide if a TM stops on the empty string (HALT), and that
this is a harder problem. We can reduce HALT to this problem as follows
1. Run M
2. When M stops erase the text and then write dm17
Now this is a reduction to this problem from HALT. 
** 2002 p. 6
*** a
Consider Sigma^* and \emptyset. Rices thrm says this is a non trivial property,
so not decidable.
*** b
Note, property of the TM. Since M has only a finite number of transition rules
it is possible to concider all of them in finite time, so it is decidable.
*** c
undecidable, since halt is regonizable, but undecidable, and thus its compliment
is not recognizable.

Undecidable, since if this was decidable then we could use it to decide HALT.
** 2003 p. 5
*** a
False. Concider L and L'. Then L cap L' = Ø  which is decidable. (note that if L' was decidable we could use it to decide L)
*** b
True, same setup -> L \cup L' = Sigma^* which is decidable.
*** c
True, note that n^3 < 100 => n^2 < 100 => n < 10, so it is a finite language, and thus regular. 
*** d
Yes, since any finite language is regular we can construct a DFA M s.t. L1 = L(M), and thus it follows that L2 \cap L(M) = L2 \cap L1.
*** e
Note that L' is regular since it is finite. Thus we can simply consider this as
an alphabet for L'*, which thus is also regular. Further note that since L' is
regular is is L'' = L. Now note that the difference of two regular languages is
also regular, and thus L \ L'* is regular, and thus also context-free.

Note that argument could have become shorter if we used simply that a regular
language is closed under *.
** 7.5
No. Concider the 4 possible assignments
| t,t | D fails |
| t,f | C fails |
| f,t | B fails |
| f,f | A fails |
** 7.6
*** Union
Let A and B be in P. Then note that we can decide them by running one after the
other. This means that it takes at most 2*max(O(A),O(B)) = O(max(O(A),O(B)))
which means that it is still polynomial.
*** Concatenation
Note we can split string n+1 places. Now we can run A+B on each of this. This is
just (n+1)(O(A)+O(B))=O(n*max(A,B)).

Same setup, but note that our new time is O(AB) = O(A) + O(B) = O(max(A,B))
*** Complement
Note that we can just check if the input is in the language, and then reverse
the output. This runs in polynomial time, since we just run the original TM,
which was polynomial.
** 7.7
*** Union
Note that we can verify each language in polynomial time, so it takes at most
the time it takes to run both verifiers to verify if it is in the union.
*** Concatenation
Just use the nondeterministic definition, and then the argument from 7.6.
** 7.8
Note that this for each node scan all nodes gives n^2. The final scan to see if
all ndoes have been marked is n, so O(n^2).
** 7.9
Note that for a graph with n vertices we can concider all 3-combinations of
graphs O(n^3), and then for each combination we can see if there is 3 edges
connecting these vertices in n time, for a total of O(n^4).
** 7.12
To see that it is in NP note that given an isomorphism pi from G to H we simply
have to check if every edge from a to b is mapped to an edge going pi(a) to
pi(b). If this is the case (and we are sure pi is an isomorphism) it holds, i.e.
is verified in O(n) time, where n is the number of edges.
** 34.3.6
Note that for any other language we have string both inside, and outside the
language, so our reduction will simply be "decide the language L' in polynomial
time. If accept pic w in L, if nto pic w outside L". For both Ø and Sigma^* we
fail to do this, since we cannot find a word inside and a word outside the
language.
** 34.3.7
???
** 34.4.7
???
** 34.5.2
???
** 34.5.7
???
* Week 12
** 34-3
*** b
Note that we can always colour it with n (number of vertices in graph) colours,
so we can try from 1 up to n colours, so linear time.

Note that the other direction it is just the question is "if we can do it with k
colours". Thus we can just solve the other problem, and if it is smaller than or
equal to k we return true.
*** c
We could reduce 3-colour to this problem by simply using k = 3.

To see that it is NP note that we have a verifier by simply going over the edges
and making sure that the vertices they connect to are different colours.
*** d
Note we only need to consider two colours, true and false. Now, for any clause
we connect as described in the book. 
** 35.1-4
Note that for the root we must have one of the two edges. Then we now have kinda
3 trees, but we have to consider taking either one of the top edges of our top
trees, or taking the edge above and one of the ones below. 

I'm an idiot, this was  vertex cover...

Look for edges (u,v) s.t. v is a lead. Then take u (note that we need to take
eith one of them since v is a leaf), and u cannot be worse than v, since v is a
leaf. Now consider S' where we have removed all edges that are covered and repeat on this subgraph. 
** 35.1-5
* Week 15
** 35.1
*** a
Just divide all the numbers in subset-sum with sum(numbers)/m where m is the
number of subsets you want, and then the question is if we can pack them in m
bins.
*** b
An ideal solution will be when all, but possibly one, of the bins are full. In
that case we will need exactly ceil(S) bins.
*** c
Assume we have one halfful bin, and look at the new element. Maybe we can fit it
into a bin before the halfful, in which case we move on to the next. If we
cannot put it in the halfful bin that means that it is more than .5, so even if
we put it in an entirely new bin that one is not half ful, so we get still only
one. If we can fit it in the halfful one, we might even have 0 halfful ones.
*** d
Assuming we have more than ceil(S) bins, then there are at least two that are
less than halfful, a contradiction to c.
*** e
Is it really just that optimal is S':= ceil(S) and approx is at most 2S', so
approx ratio is 2S'/S' = 2?
** 35.7
Thomas claims that in problem b we get to resort the list by value pr weight. 

He is wrong, but so am I. I noted that in b we only try to solve Q_j, and not Q.
*** a
Note that there is a first item an optimal solution contains. Since P_j contains
all items n > j, and includes item j in the bag it is an optimal solution.
*** b
There is a polynomial solution to this, and it is exactly a greedy algorithm,
that works like this.
*** c
if v_i/w_i > v_j/w_/j we will ALWAYS take the first, until we run out of either
the item or space in the bag. Only then (when we have entire item i) will we
start considering any other thing.
*** d
Counter example: Assume capacity of 100, 1 lbs of 10$ value, 100lbs of
100$value. Q_i takes all of item 1, and 99% of item 2, total value 109$. R_j
removes the 99%, and ends up with only value 10$, so much less.

Fails since we assumed that they are ordered by their value, so item 2 would be
first. However it doesn't fail when we sort by weight pr pound, and if we don't
(b) fails.

Solution: Note that we have that the total value of whatever we have a fraction
of is less than that of item i, that we have the entirety of. Thus first
inequality follows. For the 2nd note that it follows trivially, since Q_i >=
P_i, otherwise we would take Q_i = P_i.
*** e
** 5
We should always start with those that have nothing coming out of it. Note that
the algorithm will always try to add arrows that follow the same direction as
whatever we already have.
** 7
This is doable.


